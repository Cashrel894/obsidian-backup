#CS188 
在某些问题中，我们不关心到达目标状态的路径，只关心最优的目标状态，例如数独游戏。

在**局部搜索算法**(Local Search Algorithm) 中，状态空间包含所有完整解的集合，我们需要找到一个满足特定约束或最优化某些目标函数的解。![[Pasted image 20260217184032.png]]

## Hill-Climbing Search
**爬山算法**(Hill-Climbing Search)，或称**最陡上升**(Steepest-Ascent)，主要思想是从当前状态转移到提高目标值最多的相邻状态。这个算法不维护搜索树，而只会追踪一个状态集合和对应的目标值。

爬山算法的**贪婪性**可能导致算法终止于**局部最大值** (Local Maxima) 或**高原**(Plateaus)。其中高原指的是状态空间中的水平区域，向邻近状态的转移不会增大目标值，如“平原局部最大值”(Flat Local Maxima)或“肩膀”(Shoulder)。

**随机爬山算法**(Stochastic Hill-Climbing Search) 是爬山算法的一个变种，会在所有提高目标值的行动中随机选取一个，而不是只选取提高目标值最多的；这个变种收敛速度更慢，但更有可能收敛到更高的目标值。

另一个变种是**随机横向移动**(Random Sideways Moves)，允许那些非严格增加目标值的行动，可以避免卡在“肩膀”处。
![[Pasted image 20260218165721.png]]

此外，**随机重启爬山算法**(Random-restart Hill-Climbing) 从多个随机的初始状态出发，多次执行爬山算法，可以有效提高爬山算法的完整性。

## Simulated Annealing Search
**模拟退火算法**(Simulated Annealing Search)结合了**随机游走**和**爬山算法**的思想，允许状态有一定概率往降低目标值的方向移动。而这个概率随着算法进行不断降低，以期将状态稳定在最大值。

具体来说，在每个时间戳，算法会随机选择一个行动：
- 如果转移到目标值更**高**的状态，该行动**总是**会被接受。
- 如果转移到目标值更**低**的状态，该行动**有一定概率**被接受。而这个概率被**温度系数**(Temperature Parameter) 所决定，在初始时通常很高，随后根据**计划**(Schedule) 随时间降低。
理论上，如果温度降低得足够慢，模拟退火算法有接近 100% 的概率到达全局最大值。
![[Pasted image 20260218170726.png]]

## Local Beam Search
**局部束搜索**(Local Beam Search) 也是爬山算法的一个变种，该算法会同时追踪 $\displaystyle k$ 个状态（也称为**线程**），并且在每次迭代中，会在这 $\displaystyle k$ 个线程的所有子状态集合中，选取 $\displaystyle k$ 个使目标值最大的状态作为新的线程，从而不断迭代，直到找到全局最大值为止。

该算法与爬山算法的核心差异在于，$\displaystyle k$ 个线程之间的信息可以共享，足够高的目标值可以“吸引”其他线程加入搜索，从而提高搜索效率。

不过，局部束搜索有时也会卡在“平原”区域，需要采用变种**随机束搜索**(Stochastic Beam Search) 规避。

## Genetic Algorithms
**遗传算法**(Genetic Algorithm)是局部束搜索的一个变种，被广泛应用于各种优化问题中。

遗传算法由 $\displaystyle k$ 个随机选取的初始状态开始，作为**总体**(Population)，其中的状态称为**个体**(Individual)。所有个体都由一个字符种类有限的字符串编码。

首先，算法会随机选取个体对，进行**繁殖**(Reproduce)。每个个体会被**适应度函数**(Fitness Function) 评估，一个个体的适应度越高，被算法选中的概率也越高。

接着，每个个体对的两个个体会由一个**随机的分界点**发生**交叉互换**(Crossover)：即，编码字符串在分界点以前的部分不变，分界点以后的部分**互换**。

最后，以一个较小的概率随机发生**基因突变**(Mutation)，这样得到的所有个体将组成新的总体，进行下一轮繁殖。

![[Pasted image 20260218171715.png]]